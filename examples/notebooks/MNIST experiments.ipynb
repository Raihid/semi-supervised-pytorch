{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "cuda = torch.cuda.is_available()\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend(\"agg\")\n",
    "import sys\n",
    "sys.path.append(\"../../semi-supervised\")\n",
    "\n",
    "from models import AuxiliaryDeepGenerativeModel, DeepGenerativeModel, StackedDeepGenerativeModel, VariationalAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../semi-supervised/models/vae.py:238: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After VAE\n",
      "50\n",
      "VariationalAutoencoder(\n",
      "  (encoder): Encoder(\n",
      "    (first_dense): ModuleList(\n",
      "      (0): Linear(in_features=784, out_features=500, bias=True)\n",
      "    )\n",
      "    (hidden): ModuleList(\n",
      "      (0): Softplus(beta=1, threshold=20)\n",
      "      (1): Linear(in_features=500, out_features=500, bias=True)\n",
      "      (2): Softplus(beta=1, threshold=20)\n",
      "    )\n",
      "    (sample): GaussianSample(\n",
      "      (mu): Linear(in_features=500, out_features=50, bias=True)\n",
      "      (log_var): Linear(in_features=500, out_features=50, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (first_dense): ModuleList(\n",
      "      (0): Linear(in_features=50, out_features=500, bias=True)\n",
      "    )\n",
      "    (hidden): ModuleList(\n",
      "      (0): Softplus(beta=1, threshold=20)\n",
      "      (1): Linear(in_features=500, out_features=500, bias=True)\n",
      "      (2): Softplus(beta=1, threshold=20)\n",
      "    )\n",
      "    (reconstruction): Linear(in_features=500, out_features=784, bias=True)\n",
      "  )\n",
      ") DeepGenerativeModel(\n",
      "  (encoder): Encoder(\n",
      "    (first_dense): ModuleList(\n",
      "      (0): Linear(in_features=50, out_features=300, bias=True)\n",
      "      (1): Linear(in_features=10, out_features=300, bias=True)\n",
      "    )\n",
      "    (hidden): ModuleList(\n",
      "      (0): Softplus(beta=1, threshold=20)\n",
      "    )\n",
      "    (sample): GaussianSample(\n",
      "      (mu): Linear(in_features=300, out_features=50, bias=True)\n",
      "      (log_var): Linear(in_features=300, out_features=50, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (first_dense): ModuleList(\n",
      "      (0): Linear(in_features=50, out_features=300, bias=True)\n",
      "      (1): Linear(in_features=10, out_features=300, bias=True)\n",
      "    )\n",
      "    (hidden): ModuleList(\n",
      "      (0): Softplus(beta=1, threshold=20)\n",
      "    )\n",
      "    (reconstruction): Linear(in_features=300, out_features=50, bias=True)\n",
      "  )\n",
      "  (classifier): Classifier(\n",
      "    (first_dense): ModuleList(\n",
      "      (0): Linear(in_features=50, out_features=300, bias=True)\n",
      "    )\n",
      "    (hidden): ModuleList(\n",
      "      (0): Softplus(beta=1, threshold=20)\n",
      "    )\n",
      "    (logits): Linear(in_features=300, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "After stacked\n",
      "784\n",
      "[784, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../../semi-supervised/models/dgm.py:109: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "  init.xavier_normal(m.weight.data)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AuxiliaryDeepGenerativeModel(\n",
       "  (encoder): Encoder(\n",
       "    (first_dense): ModuleList(\n",
       "      (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "      (1): Linear(in_features=10, out_features=500, bias=True)\n",
       "      (2): Linear(in_features=100, out_features=500, bias=True)\n",
       "    )\n",
       "    (hidden): ModuleList(\n",
       "      (0): ReLU()\n",
       "      (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (sample): GaussianSample(\n",
       "      (mu): Linear(in_features=500, out_features=100, bias=True)\n",
       "      (log_var): Linear(in_features=500, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (first_dense): ModuleList(\n",
       "      (0): Linear(in_features=100, out_features=500, bias=True)\n",
       "      (1): Linear(in_features=10, out_features=500, bias=True)\n",
       "    )\n",
       "    (hidden): ModuleList(\n",
       "      (0): ReLU()\n",
       "      (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (reconstruction): Linear(in_features=500, out_features=784, bias=True)\n",
       "  )\n",
       "  (classifier): Classifier(\n",
       "    (first_dense): ModuleList(\n",
       "      (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "      (1): Linear(in_features=100, out_features=500, bias=True)\n",
       "    )\n",
       "    (hidden): ModuleList(\n",
       "      (0): ReLU()\n",
       "      (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (logits): Linear(in_features=500, out_features=10, bias=True)\n",
       "  )\n",
       "  (aux_encoder): Encoder(\n",
       "    (first_dense): ModuleList(\n",
       "      (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "    )\n",
       "    (hidden): ModuleList(\n",
       "      (0): ReLU()\n",
       "      (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (sample): GaussianSample(\n",
       "      (mu): Linear(in_features=500, out_features=100, bias=True)\n",
       "      (log_var): Linear(in_features=500, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (aux_decoder): Encoder(\n",
       "    (first_dense): ModuleList(\n",
       "      (0): Linear(in_features=784, out_features=500, bias=True)\n",
       "      (1): Linear(in_features=10, out_features=500, bias=True)\n",
       "      (2): Linear(in_features=100, out_features=500, bias=True)\n",
       "    )\n",
       "    (hidden): ModuleList(\n",
       "      (0): ReLU()\n",
       "      (1): Linear(in_features=500, out_features=500, bias=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (sample): GaussianSample(\n",
       "      (mu): Linear(in_features=500, out_features=100, bias=True)\n",
       "      (log_var): Linear(in_features=500, out_features=100, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = VariationalAutoencoder(\n",
    "    [784, 50, [500, 500]],\n",
    "    batch_norm=False,\n",
    "    activation_fn=torch.nn.Softplus).cuda()\n",
    "features.load_state_dict(torch.load(\"./vae_mnist_new.ckpt\"))\n",
    "\n",
    "print(\"After VAE\")\n",
    "stacked = StackedDeepGenerativeModel(\n",
    "    [784, 10, 50, [300]], features,\n",
    "    batch_norm=False,\n",
    "    activation_fn=torch.nn.Softplus)\n",
    "stacked.dgm.load_state_dict(torch.load(\"./m1m2_mnist_new.ckpt\"))\n",
    "stacked.dgm = stacked.dgm.cuda()\n",
    "print(stacked.features, stacked.dgm)\n",
    "print(\"After stacked\")\n",
    "\n",
    "adgm = AuxiliaryDeepGenerativeModel([784, 10, 100, 100, [500, 500]], batch_norm=False)\n",
    "adgm.load_state_dict(torch.load(\"./adgm_mnist_new.ckpt\"))\n",
    "adgm = adgm.cuda()\n",
    "adgm\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datautils import get_mnist, get_svhn\n",
    "\n",
    "labelled, unlabelled, validation, mnist_mean, mnist_std = get_mnist(location=\"./\", batch_size=100, labels_per_class=10, preprocess=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mwolczyk/miniconda3/envs/pytorch_nightly/lib/python3.7/site-packages/torch/nn/functional.py:1382: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "adgm.eval()\n",
    "stacked.dgm.eval()\n",
    "z_dim = 100\n",
    "\n",
    "z = torch.randn(100, z_dim).cuda()\n",
    "y = np.zeros((100, 10))\n",
    "y[np.arange(100), np.arange(100) // 10] = 1.\n",
    "y = torch.tensor(y, dtype=torch.float).cuda()\n",
    "\n",
    "x_mu = adgm.sample(z, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADGM test error 4.0399932861328125\n",
      "Stacked test error 17.04998779296875\n"
     ]
    }
   ],
   "source": [
    "adgm.eval()\n",
    "\n",
    "accuracy = 0.\n",
    "for x, y in validation:\n",
    "\n",
    "    if cuda:\n",
    "        x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "\n",
    "    # x, _, _ = features.encoder(x)\n",
    "    logits = adgm.classify(x.repeat(100, 1))\n",
    "    logits = logits.reshape(100, -1, logits.shape[-1]).mean(0)\n",
    "    _, pred_idx = torch.max(logits, 1)\n",
    "    _, lab_idx = torch.max(y, 1)\n",
    "    accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "\n",
    "print(\"ADGM test error\", 100 - accuracy.item())\n",
    "\n",
    "stacked.features.eval()\n",
    "stacked.dgm.eval()\n",
    "\n",
    "accuracy = 0.\n",
    "for x, y in validation:\n",
    "\n",
    "    if cuda:\n",
    "        x, y = x.cuda(device=0), y.cuda(device=0)\n",
    "        \n",
    "    x, _, _ = stacked.features.encoder(x)\n",
    "    logits = stacked.dgm.classify(x.repeat(100, 1))\n",
    "    logits = logits.reshape(100, -1, logits.shape[-1]).mean(0)\n",
    "    _, pred_idx = torch.max(logits, 1)\n",
    "    _, lab_idx = torch.max(y, 1)\n",
    "    accuracy += torch.mean((torch.max(logits, 1)[1].data == torch.max(y, 1)[1].data).float())\n",
    "    \n",
    "print(\"Stacked test error\", 100 - accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(10, 10, figsize=(10, 10))\n",
    "\n",
    "samples = x_mu.cpu().data.view(-1, 28, 28).numpy()\n",
    "# samples = x_mu.data.view(-1, 3, 32, 32).cpu().numpy().transpose(0, 2, 3, 1)\n",
    "\n",
    "\n",
    "# mnist_means = np.tile(mnist_mean.reshape((1, -1)), (len(samples), 1))\n",
    "# mnist_means[:, mnist_std > 0.1] = samples\n",
    "# samples = mnist_means.reshape(-1, 28, 28)\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.imshow(samples[i], cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from metrics import sample_from_classes, interpolation, cyclic_interpolation, save_samples\n",
    "stacked.features.eval()\n",
    "stacked.dgm.eval()\n",
    "\n",
    "im_shape = [28, 28, 1]\n",
    "classes_num = 10\n",
    "z_dim = 100\n",
    "labels_names = [str(idx) for idx in range(10)]\n",
    "\n",
    "cyclic_interpolation(\"adgm_mnist\", adgm, validation.dataset, im_shape, classes_num, labels_names)\n",
    "cyclic_interpolation(\"m1m2_mnist\", stacked, validation.dataset, im_shape, classes_num, labels_names)\n",
    "\n",
    "interpolation(\"adgm_mnist\", adgm, validation.dataset, im_shape)\n",
    "interpolation(\"m1m2_mnist\", stacked, validation.dataset, im_shape)\n",
    "\n",
    "sample_from_classes(\"adgm_mnist\", adgm, im_shape, 100, classes_num)\n",
    "sample_from_classes(\"m1m2_mnist\", stacked, im_shape, 50, classes_num)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_samples(\"adgm_mnist\", adgm, im_shape, 10000, classes_num, 100)\n",
    "save_samples(\"m1m2_mnist\", stacked, im_shape, 10000, classes_num, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
